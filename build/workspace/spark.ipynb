{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02dbd35c-c05b-4e74-9cb5-a3fc2a0e5351",
   "metadata": {},
   "source": [
    "### Start SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fcf1a3f-7641-4f37-9935-eb1cd80bf098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Активные Spark сессии: http://macbookpro:4040\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .appName(\"halltape_pyspark_local\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "print(\"Активные Spark сессии:\", spark.sparkContext.uiWebUrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f81f1bb-00ec-4840-8998-0d2056e81e26",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2030acf5-9a3b-445b-87d3-9727ad4e3dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/customs_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e72cd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 _c0|\n",
      "+--------------------+\n",
      "|month;country;cod...|\n",
      "|01/2016;IT;620469...|\n",
      "|01/2016;CN;900190...|\n",
      "|01/2016;BY;841430...|\n",
      "|01/2016;US;901850...|\n",
      "|01/2016;EE;902110...|\n",
      "|01/2016;FR;381600...|\n",
      "|01/2016;MX;852351...|\n",
      "|01/2016;JP;620452...|\n",
      "|01/2016;KR;611020...|\n",
      "|01/2016;KG;852713...|\n",
      "|01/2016;ZA;842123...|\n",
      "|01/2016;CN;851810...|\n",
      "|01/2016;TR;841790...|\n",
      "|01/2016;IT;390610...|\n",
      "|01/2016;CZ;870840...|\n",
      "|01/2016;ES;640419...|\n",
      "|01/2016;IT;940490...|\n",
      "|01/2016;UA;820780...|\n",
      "|01/2016;CN;330410...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.csv(PATH).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83700e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+------+-----+--------+------+--------+-------------+-----------+--------------------+\n",
      "|  month|country|      code| value|netto|quantity|region|district|direction_eng|measure_eng|           load_date|\n",
      "+-------+-------+----------+------+-----+--------+------+--------+-------------+-----------+--------------------+\n",
      "|01/2016|     IT|6204695000|   131|    1|       7| 46000|      01|           IM|        ShT|2024-07-01T00:00:...|\n",
      "|01/2016|     CN|9001900009|112750|   18|       0| 46000|      01|           IM|          1|2024-01-01T00:00:...|\n",
      "|01/2016|     BY|8414302004|   392|   57|       8| 50000|      06|           IM|        ShT|2024-06-01T00:00:...|\n",
      "|01/2016|     US|9018509000| 54349|  179|       0| 40000|      02|           IM|          1|2024-04-01T00:00:...|\n",
      "|01/2016|     EE|9021101000| 17304|  372|       0| 46000|      01|           IM|          1|2024-02-01T00:00:...|\n",
      "+-------+-------+----------+------+-----+--------+------+--------+-------------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.csv(PATH, sep=';', header=True).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c9440ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+------+------+--------+------+--------+-------------+-----------+-----------------------------+\n",
      "|month  |country|code      |value |netto |quantity|region|district|direction_eng|measure_eng|load_date                    |\n",
      "+-------+-------+----------+------+------+--------+------+--------+-------------+-----------+-----------------------------+\n",
      "|01/2016|IT     |6204695000|131   |1     |7       |46000 |01      |IM           |ShT        |2024-07-01T00:00:00.000+03:00|\n",
      "|01/2016|CN     |9001900009|112750|18    |0       |46000 |01      |IM           |1          |2024-01-01T00:00:00.000+03:00|\n",
      "|01/2016|BY     |8414302004|392   |57    |8       |50000 |06      |IM           |ShT        |2024-06-01T00:00:00.000+03:00|\n",
      "|01/2016|US     |9018509000|54349 |179   |0       |40000 |02      |IM           |1          |2024-04-01T00:00:00.000+03:00|\n",
      "|01/2016|EE     |9021101000|17304 |372   |0       |46000 |01      |IM           |1          |2024-02-01T00:00:00.000+03:00|\n",
      "|01/2016|FR     |3816000000|323488|253600|0       |40000 |02      |IM           |1          |2024-02-01T00:00:00.000+03:00|\n",
      "|01/2016|MX     |8523519300|1611  |0     |4       |40000 |02      |IM           |ShT        |2024-04-01T00:00:00.000+03:00|\n",
      "|01/2016|JP     |6204520000|29    |1     |2       |46000 |01      |IM           |ShT        |2024-02-01T00:00:00.000+03:00|\n",
      "|01/2016|KR     |6110209100|815   |2     |5       |46000 |01      |IM           |ShT        |2024-01-01T00:00:00.000+03:00|\n",
      "|01/2016|KG     |8527139900|11868 |2127  |2630    |46000 |01      |IM           |ShT        |2024-06-01T00:00:00.000+03:00|\n",
      "|01/2016|ZA     |8421230000|12686 |1785  |3451    |45000 |01      |IM           |ShT        |2024-03-01T00:00:00.000+03:00|\n",
      "|01/2016|CN     |8518109500|12    |0     |10      |65000 |05      |IM           |ShT        |2024-03-01T00:00:00.000+03:00|\n",
      "|01/2016|TR     |8417900000|206453|17297 |1       |92000 |04      |IM           |ShT        |2024-06-01T00:00:00.000+03:00|\n",
      "|01/2016|IT     |3906100000|4492  |1075  |0       |45000 |01      |IM           |1          |2024-02-01T00:00:00.000+03:00|\n",
      "|01/2016|CZ     |8708409909|41    |2     |0       |46000 |01      |IM           |1          |2024-01-01T00:00:00.000+03:00|\n",
      "|01/2016|ES     |6404191000|11822 |346   |760     |45000 |01      |IM           |PAR        |2024-01-01T00:00:00.000+03:00|\n",
      "|01/2016|IT     |9404909000|6801  |485   |0       |46000 |01      |IM           |1          |2024-03-01T00:00:00.000+03:00|\n",
      "|01/2016|UA     |8207801900|35793 |1020  |0       |14000 |01      |IM           |1          |2024-02-01T00:00:00.000+03:00|\n",
      "|01/2016|CN     |3304100000|59678 |10829 |0       |46000 |01      |IM           |1          |2024-06-01T00:00:00.000+03:00|\n",
      "|01/2016|SI     |6104440000|1470  |13    |15      |45000 |01      |IM           |ShT        |2024-05-01T00:00:00.000+03:00|\n",
      "+-------+-------+----------+------+------+--------+------+--------+-------------+-----------+-----------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-RECORD 0--------------------------------------\n",
      " month         | 01/2016                       \n",
      " country       | IT                            \n",
      " code          | 6204695000                    \n",
      " value         | 131                           \n",
      " netto         | 1                             \n",
      " quantity      | 7                             \n",
      " region        | 46000                         \n",
      " district      | 01                            \n",
      " direction_eng | IM                            \n",
      " measure_eng   | ShT                           \n",
      " load_date     | 2024-07-01T00:00:00.000+03:00 \n",
      "-RECORD 1--------------------------------------\n",
      " month         | 01/2016                       \n",
      " country       | CN                            \n",
      " code          | 9001900009                    \n",
      " value         | 112750                        \n",
      " netto         | 18                            \n",
      " quantity      | 0                             \n",
      " region        | 46000                         \n",
      " district      | 01                            \n",
      " direction_eng | IM                            \n",
      " measure_eng   | 1                             \n",
      " load_date     | 2024-01-01T00:00:00.000+03:00 \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(PATH, sep=';', header=True)\n",
    "\n",
    "df.show(truncate=False)\n",
    "\n",
    "df.show(2, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf84d9-46e3-484d-bb00-67c815628c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PrintSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21a90f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      " |-- netto: string (nullable = true)\n",
      " |-- quantity: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- district: string (nullable = true)\n",
      " |-- direction_eng: string (nullable = true)\n",
      " |-- measure_eng: string (nullable = true)\n",
      " |-- load_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccf633ef-415f-417d-b3b8-fb56b5109029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['month',\n",
       " 'country',\n",
       " 'code',\n",
       " 'value',\n",
       " 'netto',\n",
       " 'quantity',\n",
       " 'region',\n",
       " 'district',\n",
       " 'direction',\n",
       " 'measure',\n",
       " 'load_date']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df\\\n",
    "            .withColumnRenamed(\"direction_eng\", \"direction\")\\\n",
    "            .withColumnRenamed(\"measure_eng\", \"measure\")\n",
    "\n",
    "result.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8464d803",
   "metadata": {},
   "source": [
    "### Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c67966ef-90cd-42d4-a260-236b60220312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:=================================================>      (14 + 2) / 16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|country|\n",
      "+-------+\n",
      "|LT     |\n",
      "|MM     |\n",
      "|DZ     |\n",
      "|CI     |\n",
      "|TC     |\n",
      "|FI     |\n",
      "|SC     |\n",
      "|AZ     |\n",
      "|UA     |\n",
      "|RO     |\n",
      "+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "result.select('country').distinct().show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799d080a-b5e8-45cb-aec0-8e03eb5e5bb7",
   "metadata": {},
   "source": [
    "### GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d94e8c7-41df-4a64-a0db-e302111f05d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:================================>                        (9 + 7) / 16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|country|total_rows|\n",
      "+-------+----------+\n",
      "|     BY|   3509568|\n",
      "|     KZ|   2519896|\n",
      "|     CN|   2454792|\n",
      "|     DE|   1542311|\n",
      "|     UA|   1158498|\n",
      "|     IT|   1102837|\n",
      "|     US|    835936|\n",
      "|     PL|    666690|\n",
      "|     FR|    593040|\n",
      "|     JP|    571756|\n",
      "|     TR|    463432|\n",
      "|     KR|    446907|\n",
      "|     GB|    443091|\n",
      "|     AM|    438705|\n",
      "|     CZ|    407360|\n",
      "|     KG|    403565|\n",
      "|     ES|    401644|\n",
      "|     IN|    374151|\n",
      "|     NL|    365193|\n",
      "|     UZ|    329707|\n",
      "+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "result\\\n",
    "    .groupBy('country')\\\n",
    "    .agg(F.count('*').alias('total_rows'))\\\n",
    "    .orderBy(F.col('total_rows').desc())\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f564628-8bf3-45cb-95f2-6f80ed4cec6a",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cd2a20f-8af3-439a-a487-6c7d3fbcc64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:================================>                        (9 + 7) / 16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Два варианта написании фильтрации\n",
    "df_de = result\\\n",
    "            .where(F.col('country') == 'DE')\\\n",
    "            .where(F.col('value').isNotNull())\n",
    "\n",
    "df_de2 = result\\\n",
    "            .where(''' country == \"DE\" ''')\\\n",
    "            .where(''' value IS NOT NULL ''')\n",
    "\n",
    "print(df_de.count() == df_de2.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b564c-86f8-4633-a5ff-5cf8da7b6eea",
   "metadata": {},
   "source": [
    "### Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7058846-f7b2-4a9e-9388-3a5a9ed26bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+-----+-----+--------+------+--------+---------+-------+-----------------------------+\n",
      "|month  |country|code      |value|netto|quantity|region|district|direction|measure|load_date                    |\n",
      "+-------+-------+----------+-----+-----+--------+------+--------+---------+-------+-----------------------------+\n",
      "|01/2016|DE     |4016995709|5901 |172  |0       |46000 |01      |IM       |1      |2024-01-01T00:00:00.000+03:00|\n",
      "|01/2016|DE     |8708809109|1213 |94   |0       |45000 |01      |IM       |1      |2024-01-01T00:00:00.000+03:00|\n",
      "+-------+-------+----------+-----+-----+--------+------+--------+---------+-------+-----------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_de.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "945d5e8c-c146-4221-9a29-9279d6911de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['month',\n",
       " 'country',\n",
       " 'code',\n",
       " 'value',\n",
       " 'netto',\n",
       " 'quantity',\n",
       " 'region',\n",
       " 'district',\n",
       " 'direction',\n",
       " 'measure',\n",
       " 'load_date']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_de.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d62869a2-9781-428d-9292-6775b5bd5b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+-----+-----+--------+------+--------+---------+-------+----------+\n",
      "|month  |country|code      |value|netto|quantity|region|district|direction|measure|load_date |\n",
      "+-------+-------+----------+-----+-----+--------+------+--------+---------+-------+----------+\n",
      "|01/2016|DE     |4016995709|5901 |172  |0       |46000 |01      |IM       |1      |2024-01-01|\n",
      "|01/2016|DE     |8708809109|1213 |94   |0       |45000 |01      |IM       |1      |2024-01-01|\n",
      "+-------+-------+----------+-----+-----+--------+------+--------+---------+-------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final = df_de\\\n",
    "            .select('month',\n",
    "                    'country',\n",
    "                    'code',\n",
    "                    'value',\n",
    "                    'netto',\n",
    "                    'quantity',\n",
    "                    'region',\n",
    "                    'district',\n",
    "                    'direction',\n",
    "                    'measure',\n",
    "                    F.col('load_date').cast('date'))\n",
    "\n",
    "final.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8eff1058-85c4-4f3a-ad43-b3e69f41abab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во партиций 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во партиций 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load_date distinct: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 74:===================================>                    (10 + 6) / 16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во партиций 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 74:=============================================>          (13 + 3) / 16]"
     ]
    }
   ],
   "source": [
    "# Сохранение неконтроллируемое по кол-ву файлов\n",
    "final\\\n",
    "    .write\\\n",
    "    .format('csv')\\\n",
    "    .options(header='True', sep=';')\\\n",
    "    .csv('data/final_no_control')\n",
    "\n",
    "partition_num = final.rdd.getNumPartitions()\n",
    "print(f'Кол-во партиций {partition_num}')\n",
    "\n",
    "# Сохранение контроллируемое по кол-ву файлов - ОДИН ФАЙЛ\n",
    "final\\\n",
    "    .coalesce(1)\\\n",
    "    .write\\\n",
    "    .format('csv')\\\n",
    "    .options(header='True', sep=';')\\\n",
    "    .csv('data/final_one_file') \n",
    "\n",
    "partition_num = final.coalesce(1).rdd.getNumPartitions()\n",
    "print(f'Кол-во партиций {partition_num}')\n",
    "\n",
    "\n",
    "# Сохранения с партицированием\n",
    "final\\\n",
    "    .write\\\n",
    "    .partitionBy('load_date')\\\n",
    "    .format('csv')\\\n",
    "    .options(header='True', sep=';')\\\n",
    "    .csv('data/final_partitioned')\n",
    "\n",
    "print_df = final.select('load_date').distinct()\n",
    "print(f'Load_date distinct: {print_df.count()}')\n",
    "\n",
    "\n",
    "# Сохранения с партицированием и repartition внутри самой партиции\n",
    "final\\\n",
    "    .repartition(1, 'load_date')\\\n",
    "    .write\\\n",
    "    .partitionBy('load_date')\\\n",
    "    .format('csv')\\\n",
    "    .options(header='True', sep=';')\\\n",
    "    .csv('data/final_partitioned_repart')\n",
    "\n",
    "partition_num = final.repartition(1, 'load_date').rdd.getNumPartitions()\n",
    "print(f'Кол-во партиций {partition_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f71e8-ab17-4104-85d1-fc55f3f9a43f",
   "metadata": {},
   "source": [
    "### Read Transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e081b2fd-85d9-4d14-9631-53b82a09e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "70e3d82e-b20d-4e3d-8ad9-e752662da308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350998"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_no_control = spark\\\n",
    "                        .read\\\n",
    "                        .csv('data/final_no_control/', header=True, sep=';')\\\n",
    "                        .where(''' load_date = \"2024-01-01\" ''')\n",
    "\n",
    "reader_final_one_file = spark\\\n",
    "                            .read\\\n",
    "                            .csv('data/final_one_file/', header=True, sep=';')\\\n",
    "                            .where(''' load_date = \"2024-01-01\" ''')\n",
    "\n",
    "reader_partitioned = spark\\\n",
    "                        .read\\\n",
    "                        .csv('data/final_partitioned', header=True, sep=';')\\\n",
    "                        .where(''' load_date = \"2024-01-01\" ''')\n",
    "\n",
    "reader_partitioned_repart = spark\\\n",
    "                                .read\\\n",
    "                                .csv('data/final_partitioned_repart', header=True, sep=';')\\\n",
    "                                .where(''' load_date = \"2024-01-01\" ''')\n",
    "\n",
    "\n",
    "reader_no_control.count() # number of files read: 16 | size of files read: 88.4 MiB | 2.5 s (90 ms, 301 ms, 384 ms)\n",
    "\n",
    "reader_final_one_file.count() # number of files read: 1 | size of files read: 88.4 MiB | 3.2 s (306 ms, 407 ms, 420 ms )\n",
    "\n",
    "reader_partitioned.count() # number of files read: 16 | size of files read: 16.4 MiB | 305 ms (32 ms, 39 ms, 54 ms )\n",
    "\n",
    "reader_partitioned_repart.count() # number of files read: 1 | size of files read: 16.4 MiB | 179 ms (9 ms, 43 ms, 44 ms )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c3bae7d-6e6b-4311-a25d-d89fbc00bb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8deb26e1-a63e-4036-b992-08dbd15cb4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022f5468",
   "metadata": {},
   "source": [
    "### JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7d9203a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id|label|\n",
      "+---+-----+\n",
      "|  1|  foo|\n",
      "|  2|  bar|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(45000, 'pyspark'), (40000,'airflow'), (6000,'greenplum')]\n",
    "\n",
    "# region_df = spark.createDataFrame(data, schema='region_id long, name string')\n",
    "\n",
    "\n",
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        (1, \"foo\"),  # create your data here, be consistent in the types.\n",
    "        (2, \"bar\"),\n",
    "    ],\n",
    "    [\"id\", \"label\"]  # add your column names here\n",
    ")\n",
    "\n",
    "df.show()\n",
    "# mix.join(mix, \"id\", \"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba78078",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix.join(F.broadcast(mix), \"id\", \"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e9b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = mix.where(F.col(\"number\") != \"six\")\n",
    "\n",
    "mix.join(filtered, \"id\", \"anti\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c9bc17",
   "metadata": {},
   "source": [
    "### Cache | Persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2c6344db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "27936"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv('data/final_partitioned_repart', header=True, sep=';')\n",
    "\n",
    "df.cache().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f2be3547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, brand: string, actual_price: string, date: string, load_date: date]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "eedfda2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "27936"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "df = spark.read.csv('data/final_partitioned_repart', header=True, sep=';')\n",
    "\n",
    "df.persist(StorageLevel.DISK_ONLY).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1384836e",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca736bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('not_york_one_file', header=True)\n",
    "\n",
    "df.select(\"brand\")\\\n",
    "        .distinct()\\\n",
    "        .orderBy(F.col(\"brand\").desc())\\\n",
    "        .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f89ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(F.lower(\"brand\").alias(\"test_col\"))\\\n",
    "        .distinct()\\\n",
    "        .orderBy(F.col(\"brand\").asc())\\\n",
    "        .show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57480106",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_row = df\\\n",
    "            .select(F.lower(\"brand\").alias(\"test_col\"))\\\n",
    "            .distinct()\\\n",
    "            .orderBy(F.col(\"test_col\").asc())\\\n",
    "            .limit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "one_row = df\\\n",
    "            .select(F.lower(\"brand\").alias(\"test_col\"))\\\n",
    "            .distinct()\\\n",
    "            .orderBy(F.col(\"test_col\").asc())\\\n",
    "            .limit(1)\n",
    "\n",
    "\n",
    "schema = ArrayType(\n",
    "    StructType([\n",
    "        StructField(\"key\", StringType()),\n",
    "        StructField(\"value\", StringType())\n",
    "    ])\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "new_df = one_row\\\n",
    "            .withColumn(\"test\", F.from_json(\"test_col\", schema))\\\n",
    "            .withColumn(\"element\", F.explode(F.col(\"test\")))\n",
    "\n",
    "\n",
    "\n",
    "new_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9566a5",
   "metadata": {},
   "source": [
    "### Repartition & Coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "39c4a394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|number|\n",
      "+---+------+\n",
      "|  1|   one|\n",
      "|  2|   two|\n",
      "|  3| three|\n",
      "|  4|  four|\n",
      "|  5|  five|\n",
      "|  6|   six|\n",
      "|  7| seven|\n",
      "|  8| eight|\n",
      "|  9|  nine|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1,'one'), (2,'two'), (3,'three'), (4,'four'),\n",
    "        (5,'five'), (6,'six'), (7, 'seven'), (8, 'eight'),\n",
    "        (9, 'nine')]\n",
    "\n",
    "df = spark.createDataFrame(data, ['id', 'number'])\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "44e33bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Row(id=3, number='three'), Row(id=6, number='six')],\n",
       " [],\n",
       " [Row(id=1, number='one'), Row(id=2, number='two')],\n",
       " [],\n",
       " [Row(id=8, number='eight')],\n",
       " [Row(id=5, number='five'), Row(id=9, number='nine')],\n",
       " [Row(id=4, number='four')],\n",
       " [Row(id=7, number='seven')]]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Намеренно перемешаем и поделим на 8 разделов\n",
    "mix = df.repartition(8)\n",
    "mix.rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "978ee041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Row(id=1, number='one'),\n",
       "  Row(id=4, number='four'),\n",
       "  Row(id=7, number='seven'),\n",
       "  Row(id=9, number='nine')],\n",
       " [Row(id=2, number='two')],\n",
       " [Row(id=3, number='three'),\n",
       "  Row(id=5, number='five'),\n",
       "  Row(id=6, number='six'),\n",
       "  Row(id=8, number='eight')]]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix.repartition(3).rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1eb8bba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Row(id=3, number='three'), Row(id=6, number='six')],\n",
       " [Row(id=7, number='seven'),\n",
       "  Row(id=1, number='one'),\n",
       "  Row(id=2, number='two'),\n",
       "  Row(id=5, number='five'),\n",
       "  Row(id=9, number='nine')],\n",
       " [Row(id=8, number='eight'), Row(id=4, number='four')]]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix.coalesce(3).rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "255abe6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>six</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>eight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id number\n",
       "0   3  three\n",
       "1   6    six\n",
       "2   1    one\n",
       "3   2    two\n",
       "4   8  eight"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix.toPandas().head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
